# Hackathon_Terra_Signal

Um projeto de aprendizado de mÃ¡quina para previsÃ£o de churn de clientes em um conjunto de dados de empresa de telecomunicaÃ§Ãµes. Este projeto implementa um pipeline ML completo incluindo processamento de dados, treinamento do modelo, previsÃµes e uma API REST para inferÃªncia em tempo real.

## ğŸ“‹ VisÃ£o Geral do Projeto

Este projeto de hackathon visa prever o churn de clientes (a probabilidade de um cliente descontinuar seu serviÃ§o) para uma empresa de telecomunicaÃ§Ãµes fictÃ­cia chamada Terra Signal. A soluÃ§Ã£o inclui:

- **Pipeline de Processamento de Dados**: Limpar e transformar dados brutos de clientes
- **Treinamento do Modelo**: RegressÃ£o LogÃ­stica com codificaÃ§Ã£o One-Hot
- **PrevisÃµes em Lote**: Processar novos dados de clientes e gerar previsÃµes
- **API REST**: Endpoint FastAPI para previsÃµes de churn em tempo real e recomendaÃ§Ãµes

## ğŸ‘¥ Autores

- Miqueias Ayron
- AimÃ©e Ibrahim
- VinÃ­cios Rodrigues

## ğŸ“ Estrutura do Projeto

```
Hackathon_Terra_Signal/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ history.csv              # Dados histÃ³ricos de clientes com rÃ³tulos de churn
â”‚   â”œâ”€â”€ inference.csv            # Novos dados de clientes sem rÃ³tulo para previsÃ£o
â”‚   â””â”€â”€ prediction.csv           # PrevisÃµes geradas para inference.csv
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ model.pkl                # Modelo de RegressÃ£o LogÃ­stica treinado
â”‚   â””â”€â”€ transformer.pkl          # Transformador One-Hot encoder ajustado
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ NOTEBOOK.ipynb           # Notebook inicial com fluxo de trabalho bÃ¡sico
â”‚   â”œâ”€â”€ CHURN.ipynb              # AnÃ¡lise exploratÃ³ria de dados e desenvolvimento do modelo
â”‚   â””â”€â”€ history_analysis.ipynb   # AnÃ¡lise detalhada dos dados histÃ³ricos
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py                   # AplicaÃ§Ã£o FastAPI com endpoints de previsÃ£o e recomendaÃ§Ã£o
â”‚   â”œâ”€â”€ train.py                 # Script de treinamento do modelo
â”‚   â”œâ”€â”€ predict.py               # Script de previsÃ£o em lote
â”‚   â”œâ”€â”€ process.py               # UtilitÃ¡rios de processamento de dados
â”‚   â””â”€â”€ __init__.py              # InicializaÃ§Ã£o do pacote
â”œâ”€â”€ ADD_USERS.ipynb              # Notebook utilitÃ¡rio para colaboraÃ§Ã£o de workspace
â”œâ”€â”€ requirements.txt             # DependÃªncias do Python
â”œâ”€â”€ LICENSE                      # Apache License 2.0
â””â”€â”€ README.md                    # Este arquivo
```

## ğŸ”§ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos
- Python 3.8+
- pip ou conda

### InstalaÃ§Ã£o

1. Clone ou baixe o projeto:
```bash
cd c:\dev\Hackathon_Terra_Signal
```

2. Crie um ambiente virtual (opcional mas recomendado):
```bash
python -m venv .venv
.\.venv\Scripts\activate
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

## ğŸ“Š Dados

### history.csv
- **PropÃ³sito**: Conjunto de dados de treinamento com churn de clientes rotulado
- **CaracterÃ­sticas**: Demografia de clientes, uso de serviÃ§os, informaÃ§Ãµes de faturamento
- **Alvo**: Coluna `Churn` (Sim/NÃ£o)
- **Linhas**: Registros histÃ³ricos de clientes

### inference.csv
- **PropÃ³sito**: Novos dados de clientes sem rÃ³tulo para previsÃ£o
- **CaracterÃ­sticas**: Mesma estrutura de history.csv mas sem o rÃ³tulo Churn
- **SaÃ­da**: PrevisÃµes salvas em `prediction.csv`

### prediction.csv
- **PropÃ³sito**: PrevisÃµes geradas para inference.csv
- **ConteÃºdo**: Dados originais de clientes + valores de Churn previstos

## ğŸš€ Uso

### 1. Processamento de Dados
O mÃ³dulo `process.py` gerencia limpeza de dados e engenharia de caracterÃ­sticas:

```python
from src.process import process

df = process('../data/history.csv')
```

**Etapas de Processamento:**
- Converter permanÃªncia (tenure) e cobranÃ§as para formato numÃ©rico
- Preencher TotalCharges ausentes usando: `TotalCharges = tenure * MonthlyCharges`
- Criar categorias binned:
  - `tenureCategory`: Agrupa permanÃªncia em intervalos (0-11, 12-23, 24-35, 36-47, 48+)
  - `MonthlyChargesCategory`: Agrupa cobranÃ§as mensais (0-40, 41-80, 80+)

### 2. Treinamento do Modelo
Treine o modelo de previsÃ£o de churn:

```bash
python src/train.py
```

**Detalhes do Modelo:**
- **Algoritmo**: RegressÃ£o LogÃ­stica com balanceamento de classes
- **PrÃ©-processamento**: CodificaÃ§Ã£o One-Hot para variÃ¡veis categÃ³ricas
- **SaÃ­da**: 
  - `models/model.pkl` - Classificador treinado
  - `models/transformer.pkl` - Encoder ajustado

### 3. PrevisÃµes em Lote
Gere previsÃµes para novos dados:

```bash
python src/predict.py
```

Isto irÃ¡:
- Carregar o modelo treinado e o transformador
- Processar `data/inference.csv`
- Gerar previsÃµes
- Salvar resultados em `data/prediction.csv`

### 4. API REST
Inicie o servidor FastAPI para previsÃµes em tempo real:

```bash
uvicorn src.app:app --reload
```

#### Endpoints da API

**POST /predict** - Prever churn para um Ãºnico cliente
```json
SolicitaÃ§Ã£o:
{
  "gender": "Male",
  "Partner": "Yes",
  "Dependents": "No",
  "tenure": 24,
  "MonthlyCharges": 65.5,
  "TotalCharges": 1572,
  "Contract": "Month-to-month",
  ...outras caracterÃ­sticas...
}

Resposta:
{
  "Churn": "Yes"
}
```

**POST /recommend** - Obter recomendaÃ§Ãµes para reduzir risco de churn
```json
SolicitaÃ§Ã£o:
{
  "Contract": "Month-to-month",
  ...outras caracterÃ­sticas...
}

Resposta:
{
  "recommendations": [
    "Recomendar um plano de contrato de maior duraÃ§Ã£o (1 ano ou 2 anos)."
  ]
}
```

## ğŸ““ Notebooks

### NOTEBOOK.ipynb
Notebook inicial cobrindo:
- Carregamento e exploraÃ§Ã£o de dados
- Fluxo de trabalho de treinamento do modelo
- ExecuÃ§Ã£o de previsÃ£o em lote
- VisualizaÃ§Ã£o de resultados

### CHURN.ipynb
AnÃ¡lise detalhada incluindo:
- AnÃ¡lise ExploratÃ³ria de Dados (EDA)
- DistribuiÃ§Ãµes de caracterÃ­sticas e correlaÃ§Ãµes
- AnÃ¡lise de taxa de churn
- MÃ©tricas de desempenho do modelo
- VisualizaÃ§Ãµes e insights

### history_analysis.ipynb
AnÃ¡lise histÃ³rica de dados aprofundada com:
- AnÃ¡lise de segmento de cliente
- PadrÃµes de uso de serviÃ§o
- TendÃªncias de faturamento
- EstatÃ­sticas detalhadas

## ğŸ“¦ DependÃªncias Principais

| Pacote | VersÃ£o | PropÃ³sito |
|--------|--------|----------|
| pandas | 2.3.3 | ManipulaÃ§Ã£o de dados |
| scikit-learn | (via lightgbm) | Algoritmos ML & prÃ©-processamento |
| lightgbm | 4.6.0 | Gradient boosting |
| fastapi | (incluÃ­do) | Framework REST API |
| numpy | 2.3.5 | ComputaÃ§Ã£o numÃ©rica |
| matplotlib | 3.10.7 | VisualizaÃ§Ã£o de dados |
| jupyter | (via ipykernel) | Notebooks interativos |

Veja `requirements.txt` para lista completa.

## ğŸ”„ Fluxo de Trabalho

1. **Explorar Dados**: Use CHURN.ipynb para entender o conjunto de dados
2. **Preparar Dados**: process.py gerencia limpeza e engenharia de caracterÃ­sticas
3. **Treinar Modelo**: Execute `python src/train.py` para construir o modelo
4. **Fazer PrevisÃµes**: Execute `python src/predict.py` para previsÃµes em lote
5. **Implantar API**: Execute servidor FastAPI para previsÃµes em tempo real
6. **Obter Insights**: Verifique recomendaÃ§Ãµes da API para estratÃ©gias de retenÃ§Ã£o de clientes

## ğŸ“ˆ Desempenho do Modelo

O modelo de RegressÃ£o LogÃ­stica com caracterÃ­sticas categÃ³ricas codificadas em One-Hot fornece:
- ClassificaÃ§Ã£o binÃ¡ria (Churn: Sim/NÃ£o)
- Treinamento ponderado por classe para lidar com dados desbalanceados
- ImportÃ¢ncia de caracterÃ­sticas atravÃ©s de coeficientes de regressÃ£o
- RecomendaÃ§Ãµes acionÃ¡veis para retenÃ§Ã£o de clientes

## ğŸ› ï¸ Engenharia de CaracterÃ­sticas

A soluÃ§Ã£o cria caracterÃ­sticas derivadas a partir de dados brutos:

- **tenureCategory**: PermanÃªncia de cliente agrupada em 5 intervalos
- **MonthlyChargesCategory**: CobranÃ§as mensais agrupadas em 3 brackets

Essas caracterÃ­sticas categÃ³ricas melhoram a interpretabilidade e desempenho do modelo.

## ğŸ“„ LicenÃ§a

Este projeto Ã© licenciado sob a Apache License 2.0. Veja o arquivo `LICENSE` para detalhes.

## ğŸ¤ Contribuindo

Para adicionar outros membros da equipe a este workspace:
1. Use o notebook `ADD_USERS.ipynb`
2. Ou use os recursos de compartilhamento de workspace do VS Code

## ğŸ“§ Suporte

Para dÃºvidas ou problemas, entre em contato com os autores do projeto ou consulte os comentÃ¡rios do notebook individual para detalhes de implementaÃ§Ã£o especÃ­ficos.
